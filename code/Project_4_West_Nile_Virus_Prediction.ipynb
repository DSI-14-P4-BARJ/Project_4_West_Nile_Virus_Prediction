{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGAJ6EZTN2yO"
   },
   "source": [
    "# Project 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jXqaTwHKQlp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadr\n",
    "\n",
    "import myfunctions as f\n",
    "\n",
    "import io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fp8NgMyLL57s"
   },
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv('../datasets/train.csv')\n",
    "df_test = pd.read_csv('../datasets/test.csv')\n",
    "df_spray = pd.read_csv('../datasets/spray.csv')\n",
    "df_weather = pd.read_csv('../datasets/weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-437847e23df9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtraps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Trap'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Latitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'WnvPresent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlocations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Latitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "traps = df_train[['Date', 'Trap','Longitude', 'Latitude', 'WnvPresent']]\n",
    "f.gen_map()\n",
    "\n",
    "locations = traps[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "plt.scatter(locations[:,0], locations[:,1], marker='x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>Depart</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>WetBulb</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Cool</th>\n",
       "      <th>...</th>\n",
       "      <th>CodeSum</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Water1</th>\n",
       "      <th>SnowFall</th>\n",
       "      <th>PrecipTotal</th>\n",
       "      <th>StnPressure</th>\n",
       "      <th>SeaLevel</th>\n",
       "      <th>ResultSpeed</th>\n",
       "      <th>ResultDir</th>\n",
       "      <th>AvgSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>83</td>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.10</td>\n",
       "      <td>29.82</td>\n",
       "      <td>1.7</td>\n",
       "      <td>27</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>84</td>\n",
       "      <td>52</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.18</td>\n",
       "      <td>29.82</td>\n",
       "      <td>2.7</td>\n",
       "      <td>25</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>59</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>-3</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>BR</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.38</td>\n",
       "      <td>30.09</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>BR HZ</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.44</td>\n",
       "      <td>30.08</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.12</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station        Date  Tmax  Tmin Tavg Depart  DewPoint WetBulb Heat Cool  \\\n",
       "0        1  2007-05-01    83    50   67     14        51      56    0    2   \n",
       "1        2  2007-05-01    84    52   68      M        51      57    0    3   \n",
       "2        1  2007-05-02    59    42   51     -3        42      47   14    0   \n",
       "3        2  2007-05-02    60    43   52      M        42      47   13    0   \n",
       "4        1  2007-05-03    66    46   56      2        40      48    9    0   \n",
       "\n",
       "   ... CodeSum Depth Water1 SnowFall PrecipTotal StnPressure SeaLevel  \\\n",
       "0  ...             0      M      0.0        0.00       29.10    29.82   \n",
       "1  ...             M      M        M        0.00       29.18    29.82   \n",
       "2  ...      BR     0      M      0.0        0.00       29.38    30.09   \n",
       "3  ...   BR HZ     M      M        M        0.00       29.44    30.08   \n",
       "4  ...             0      M      0.0        0.00       29.39    30.12   \n",
       "\n",
       "  ResultSpeed ResultDir  AvgSpeed  \n",
       "0         1.7        27       9.2  \n",
       "1         2.7        25       9.6  \n",
       "2        13.0         4      13.4  \n",
       "3        13.3         2      13.4  \n",
       "4        11.7         7      11.9  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station          int64\n",
       "Date            object\n",
       "Tmax             int64\n",
       "Tmin             int64\n",
       "Tavg            object\n",
       "Depart          object\n",
       "DewPoint         int64\n",
       "WetBulb         object\n",
       "Heat            object\n",
       "Cool            object\n",
       "Sunrise         object\n",
       "Sunset          object\n",
       "CodeSum         object\n",
       "Depth           object\n",
       "Water1          object\n",
       "SnowFall        object\n",
       "PrecipTotal     object\n",
       "StnPressure     object\n",
       "SeaLevel        object\n",
       "ResultSpeed    float64\n",
       "ResultDir        int64\n",
       "AvgSpeed        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d81fdb50fe9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtraps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Trap'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Latitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'WnvPresent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlocations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Latitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = pd.read_csv('../datasets/train.csv')\n",
    "df_test = pd.read_csv('../datasets/test.csv')\n",
    "df_spray = pd.read_csv('../datasets/spray.csv')\n",
    "df_weather = pd.read_csv('../datasets/weather.csv')\n",
    "\n",
    "\n",
    "traps = df_train[['Date', 'Trap','Longitude', 'Latitude', 'WnvPresent']]\n",
    "f.gen_map()\n",
    "\n",
    "locations = traps[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "plt.scatter(locations[:,0], locations[:,1], marker='x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Is_Satellite'] = [1 if len(row) > 4 else 0 for row in df_train['Trap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['Is_Satellite'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Trap'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spray = df_spray.loc[df_spray['Longitude'] > -88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spray['Date'] = pd.to_datetime(df_spray['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = df_train.loc[df_train['Date'].str.contains('2013')]\n",
    "spraytest = df_spray.loc[df_spray['Date'].str.contains('2013')]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2013 = [row for row in test['Date']]\n",
    "#date2013.extend([row for row in spraytest['Date']])\n",
    "date2013 = list(dict.fromkeys(date2013))\n",
    "from datetime import datetime    \n",
    "date2013.sort(key=lambda date: datetime.strptime(date, \"%Y-%m-%d\"))\n",
    "\n",
    "\n",
    "date2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2013 = ['2013-06-07','2013-09-26']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df_train, index='Species', values='WnvPresent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Species')['WnvPresent'].mean().sort_values(ascending=False).plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = df_train.groupby('Trap')['WnvPresent','NumMosquitos'].mean().sort_values(by='WnvPresent',ascending=False)\n",
    "top10.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data=df_train,x='NumMosquitos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['Date'].isin(date2013))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in date2013:\n",
    "    nownv2013 = df_train.loc[(df_train['Date'] == i) & (df_train['WnvPresent'] == 0)]\n",
    "    wnv2013 = df_train.loc[(df_train['Date'] == i) & (df_train['WnvPresent'] == 1)]\n",
    "    if i == '2013-06-07':\n",
    "        spraying = spray2013.loc[spray2013['Date'] == i]\n",
    "    else:\n",
    "        spraying = spraying.append(spray2013.loc[spray2013['Date'] == i])\n",
    "    f.gen_map()\n",
    "    locations = nownv2013[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "    locations1 = wnv2013[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "    locations2 = spraying[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "    plt.scatter(locations2[:,0], locations2[:,1], marker='o', c='g')\n",
    "    plt.scatter(locations[:,0], locations[:,1], marker='x', c='b')\n",
    "    plt.scatter(locations1[:,0], locations1[:,1], marker='x', c='r')\n",
    "    plt.title(i)\n",
    "    plt.pause(0.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['Date','Latitude','Longitude','WnvPresent']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spray2013.groupby(['Date']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f.gen_map()\n",
    "\n",
    "locations = spray2013[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "locations1 = nownv2013[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "locations2 = wnv2013[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "plt.scatter(locations[:,0], locations[:,1], marker='o', c='g')\n",
    "plt.scatter(locations1[:,0], locations1[:,1], marker='x', c='b')\n",
    "plt.scatter(locations2[:,0], locations2[:,1], marker='x', c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spray.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Date'] = pd.to_datetime(df_train['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[pd.DatetimeIndex(df_train['Date']).year == 2011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spray_days = df_spray.groupby('Date')['Latitude','Longitude'].max()\n",
    "fig, axes = plt.subplots(5,2,figsize=(18,25))\n",
    "f.gen_map()\n",
    "for i in range(0,10):\n",
    "    df_temp = df_spray[df_spray['Date']==spray_days.index[i]]\n",
    "    origin = [41.6, -88.0]              # lat/long of origin (lower left corner)\n",
    "    upperRight = [42.1, -87.5]          # lat/long of upper right corner\n",
    "\n",
    "\n",
    "    # generate some data to overlay\n",
    "    numPoints = 50\n",
    "    lats = df_temp['Latitude']\n",
    "    longs = df_temp['Longitude']\n",
    "\n",
    "    intersection = [41.909614, -87.746134]  # co-ordinates of intersection of IL64 / IL50 according to Google Earth\n",
    "\n",
    "    if i <=4:\n",
    "        c=0\n",
    "        a = i\n",
    "    else:\n",
    "        c=1\n",
    "        a = i-5\n",
    "    # generate plot\n",
    "    \n",
    "    axes[a,c].scatter(x=longs, y=lats, c='r', s=20)\n",
    "    axes[a,c].scatter(x=intersection[1], y=intersection[0], c='b', s=60, marker='s')\n",
    "    axes[a,c].set_title(spray_days.index[i],color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.columns = df_weather.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace M, blank spaces and '-' with Nan values, while T was replace with 0.05\n",
    "# https://wgntv.com/weather/what-are-traces-of-precipitation/\n",
    "def update_cols(data):\n",
    "    data = data.replace('M', np.nan)\n",
    "    data = data.replace('-', np.nan)\n",
    "    data = data.replace(' ', np.nan)\n",
    "    data = data.replace('  T', '0.05')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = update_cols(df_weather)\n",
    "df_weather.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_columns(columns):\n",
    "    df_weather[columns] = df_weather.apply(lambda x: df_weather.iloc[::2][columns].values.repeat(2))\n",
    "    \n",
    "# Fill in the missing data from station 2 by mirroring station 1\n",
    "mirror_columns('depart')\n",
    "mirror_columns('sunrise')\n",
    "mirror_columns('sunset')\n",
    "mirror_columns('depth')\n",
    "mirror_columns('snowfall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop water1 column as its missing all the data\n",
    "df_weather.drop(['water1'], axis = 1, inplace= True)\n",
    "# Fiil up blank cells in codesum with 'MODERATE'\n",
    "df_weather['codesum'] = df_weather['codesum'].replace(np.nan, 'MODERATE')\n",
    "# Fill null values with column median\n",
    "def fill_null(columns):\n",
    "    df_weather[columns] = df_weather[columns].fillna(df_weather[columns].median())\n",
    "    \n",
    "fill_null('preciptotal')\n",
    "fill_null('avgspeed')\n",
    "fill_null('wetbulb')\n",
    "fill_null('stnpressure')\n",
    "fill_null('sealevel')\n",
    "fill_null('heat')\n",
    "fill_null('cool')\n",
    "\n",
    "# Fill null values of Tavg column with the average of Tmax and Tmin columns (Tmax + Tmin)/2\n",
    "df_weather['tavg'] = df_weather.apply(lambda row: (row['tmax'] + row['tmin']) * 0.5\n",
    "                                      if pd.isnull(row['tavg']) else row['tavg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtype_flt(columns):\n",
    "    df_weather[columns] = df_weather[columns].astype(float)\n",
    "    \n",
    "# Amend the column data type to float\n",
    "change_dtype_flt('preciptotal')\n",
    "change_dtype_flt('stnpressure')\n",
    "change_dtype_flt('sealevel')\n",
    "change_dtype_flt('avgspeed')\n",
    "change_dtype_flt('preciptotal')\n",
    "change_dtype_flt('tavg')\n",
    "change_dtype_flt('snowfall')\n",
    "\n",
    "def change_dtype_int(columns):\n",
    "    df_weather[columns] = df_weather[columns].astype(int)\n",
    "\n",
    "# Amend the column data type to string\n",
    "change_dtype_int('depart')\n",
    "change_dtype_int('wetbulb')\n",
    "change_dtype_int('heat')\n",
    "change_dtype_int('cool')\n",
    "change_dtype_int('sunrise')\n",
    "change_dtype_int('sunset')\n",
    "change_dtype_int('depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object to datetime and create individual columns for year, month and day\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
    "df_weather['year'] = df_weather['date'].dt.year\n",
    "df_weather['month'] = df_weather['date'].dt.month\n",
    "df_weather['day'] = df_weather['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to identify days with volatile weather\n",
    "df_weather['trange'] = df_weather['tmax'] - df_weather['tmin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df_weather.drop(['codesum'], axis = 1)\n",
    "# Setting up the size of the figure\n",
    "plt.figure(figsize=(15,15))\n",
    "# Insert the title \n",
    "plt.title(\"Weather Correlation Matrix\", fontsize=22) \n",
    "corr = numeric_df.corr()\n",
    "# Set up mask to be True to hide upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "heat_map = sns.heatmap(corr,mask=mask,annot=True,vmin=-1,vmax=1,cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df.hist(figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop depth and snowfall column as depth is  missing all the data while snowfall is missing > 90%\n",
    "df_weather.drop(['depth'], axis = 1, inplace= True)\n",
    "df_weather.drop(['snowfall'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix between target tavg and other features\n",
    "tavg_mat = np.abs(numeric_df.corr())\n",
    "print(tavg_mat['tavg'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix between Weather features\n",
    "corr_mat = numeric_df.corr().abs()\n",
    "weather_mat = round(corr_mat.unstack(), 4)\n",
    "weather_mat.sort_values(ascending = False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_weather, y_vars= ['resultspeed', 'avgspeed', 'preciptotal', 'sealevel'],\n",
    "             x_vars=['tavg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
